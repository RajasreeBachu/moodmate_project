{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a35a7-7246-4ccf-bd8a-d0097a93d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make plots look nice\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"Libraries imported successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8810b-6cd5-44b2-b5d0-9bc03145d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"data/songs.csv\")\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19401f-c34b-43ce-bd2a-d7af81928dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2ca28-dcfb-4730-a815-031b2ce6188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "music_info = pd.read_csv(\"data/musicInfo.csv\")\n",
    "user_history = pd.read_csv(\"data/userListeningHistory.csv\")\n",
    "\n",
    "# If fer2013 is a CSV (emotions dataset)\n",
    "fer = pd.read_csv(\"data/fer2013.csv\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"Music Info:\")\n",
    "display(music_info.head())\n",
    "\n",
    "print(\"User Listening History:\")\n",
    "display(user_history.head())\n",
    "\n",
    "print(\"FER2013 (Emotions):\")\n",
    "display(fer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321e051-3f99-4f1e-9607-8c520a16251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "music_info = pd.read_csv(\"data/Music Info.csv\")\n",
    "user_history = pd.read_csv(\"data/userListeningHistory.csv\")\n",
    "\n",
    "# If fer2013 is a CSV (emotions dataset)\n",
    "fer = pd.read_csv(\"data/fer2013.csv\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"Music Info:\")\n",
    "display(music_info.head())\n",
    "\n",
    "print(\"User Listening History:\")\n",
    "display(user_history.head())\n",
    "\n",
    "print(\"FER2013 (Emotions):\")\n",
    "display(fer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a73ba6-edad-4cd1-befc-fa29f07fb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "music_info = pd.read_csv(\"data/Music Info.csv\")\n",
    "user_history = pd.read_csv(\"data/User Listening History.csv\")\n",
    "\n",
    "# If fer2013 is a CSV (emotions dataset)\n",
    "fer = pd.read_csv(\"data/fer2013.csv\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"Music Info:\")\n",
    "display(music_info.head())\n",
    "\n",
    "print(\"User Listening History:\")\n",
    "display(user_history.head())\n",
    "\n",
    "print(\"FER2013 (Emotions):\")\n",
    "display(fer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e9251-7ff8-4a04-aacb-4a45bf88df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Music Info:\")\n",
    "music_info.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"User Listening History:\")\n",
    "user_history.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"FER2013:\")\n",
    "fer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faaf15-f8d5-4fc7-a9c2-5312a0b3381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(music_info.head())\n",
    "display(user_history.head())\n",
    "display(fer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec16e8f-c451-40fe-b16d-7b2b3006de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_info.describe(include=\"all\"))\n",
    "print(user_history.describe(include=\"all\"))\n",
    "print(fer.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccc41c-9e5e-447a-adc4-2556ce936f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(music_info[\"duration\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Song Durations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8375505-5b9a-4863-b9b7-ead0c0f41a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(music_info[\"duration_ms\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Song Durations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5e676-18f9-41d5-9bce-ab8408d0d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=music_info, x=\"genre\", order=music_info[\"genre\"].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Number of Songs per Genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df85892-3d7b-4c9a-be22-62b5c07bba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_artists = music_info[\"artist\"].value_counts().head(10)\n",
    "top_artists.plot(kind=\"bar\", figsize=(8,5))\n",
    "plt.title(\"Top 10 Artists by Song Count\")\n",
    "plt.ylabel(\"Number of Songs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a825e50-b8e7-4591-aca7-547b74e9e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history[\"user_id\"].value_counts().head(10).plot(kind=\"bar\", figsize=(8,5))\n",
    "plt.title(\"Top 10 Active Users\")\n",
    "plt.ylabel(\"Songs Listened\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573fca4-fe2a-4401-827c-a804cbbc1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a55ccc-5f55-4144-815f-1b9d7a5cf5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Music Info missing values:\")\n",
    "print(music_info.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"User History missing values:\")\n",
    "print(user_history.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"FER2013 missing values:\")\n",
    "print(fer.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0d2f1-ab37-45bb-a392-e72fbcebb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all important values are missing\n",
    "music_info = music_info.dropna(thresh=3)\n",
    "\n",
    "# Fill missing genre/artist with \"Unknown\"\n",
    "music_info[\"genre\"] = music_info[\"genre\"].fillna(\"Unknown\")\n",
    "music_info[\"artist\"] = music_info[\"artist\"].fillna(\"Unknown\")\n",
    "\n",
    "# Fill missing duration with average duration\n",
    "if \"duration\" in music_info.columns:\n",
    "    music_info[\"duration\"] = music_info[\"duration_ms\"].fillna(music_info[\"duration\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a679d06-ac3b-40ac-9d0a-c8ac0792bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history = user_history.dropna(thresh=2)\n",
    "\n",
    "# If timestamp is missing, drop those rows\n",
    "if \"timestamp\" in user_history.columns:\n",
    "    user_history = user_history.dropna(subset=[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218b5a8-f740-492b-9bfb-00d120b1dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer = fer.dropna()\n",
    "\n",
    "# Just to confirm no NaN left\n",
    "print(\"Music Info NaNs after cleaning:\", music_info.isnull().sum().sum())\n",
    "print(\"User History NaNs after cleaning:\", user_history.isnull().sum().sum())\n",
    "print(\"FER2013 NaNs after cleaning:\", fer.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d7bbb-695b-485d-aa8f-26eae549b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all important values are missing\n",
    "music_info = music_info.dropna(thresh=3)\n",
    "\n",
    "# Fill missing genre/artist with \"Unknown\"\n",
    "music_info[\"genre\"] = music_info[\"genre\"].fillna(\"Unknown\")\n",
    "music_info[\"artist\"] = music_info[\"artist\"].fillna(\"Unknown\")\n",
    "\n",
    "# Fill missing duration with average duration\n",
    "if \"duration\" in music_info.columns:\n",
    "    music_info[\"duration\"] = music_info[\"duration_ms\"].fillna(music_info[\"duration_ms\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23052034-03f6-43e0-b1f0-add164d8a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_info.dtypes)\n",
    "print(user_history.dtypes)\n",
    "print(fer.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877a9f3-7909-4837-b402-0bcae278dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_info = pd.get_dummies(music_info, columns=['genre'])\n",
    "user_history = pd.get_dummies(user_history, columns=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2559cb7-3303-48d9-ba65-5d52e540c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_info = pd.get_dummies(music_info, columns=['genre'])\n",
    "user_history = pd.get_dummies(user_history, columns=['UserID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a5562-375e-4e7c-912c-ab42b42c0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_info = pd.get_dummies(music_info, columns=['genre'])\n",
    "user_history = pd.get_dummies(user_history, columns=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaffb94-b2e7-4e5b-bef0-b86716f0d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'user_id' in user_history.columns:\n",
    "    user_history = pd.get_dummies(user_history, columns=['user_id'])\n",
    "else:\n",
    "    print(\"Column 'user_id' not found. Available columns:\", user_history.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7121fd-63cf-4202-94ac-28340cd0fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(user_history))\n",
    "print(user_history.columns)\n",
    "print(user_history['user_id'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8275c-b8ae-414f-91b8-acc773781ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if 'user_id' in user_history.columns:\n",
    "    le = LabelEncoder()\n",
    "    user_history['user_id_encoded'] = le.fit_transform(user_history['user_id'])\n",
    "    print(user_history[['user_id', 'user_id_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1f86d-3bca-498e-8c75-e1334f24cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the FER2013 dataset\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "# Check first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef500b49-a7db-45c8-b3dd-aff2b6cfda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd818e68-00c6-44b6-ab99-98d81d2f6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\Data\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031d174-77b3-44aa-b7c8-a9b2320fd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b384aa-a7cf-4aa9-aafd-eb00e45b04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\\fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feea99a-123c-43cb-875f-cef09bbc71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/Admin/Desktop/MoodMate/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fc08c-b894-4cfe-b381-c39e246931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/Admin/Desktop/MoodMate/data/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3007784-d330-43dc-ac83-6bc91e01039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51265b-7495-44ca-8d59-952d7bd51e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert pixel strings into arrays of numbers\n",
    "X = np.array([np.fromstring(p, sep=' ') for p in data['pixels']])\n",
    "y = data['emotion'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0221e2-ce44-4eb0-8b21-dc2e89e02a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)       # shape of the image data\n",
    "print(y.shape)       # shape of the labels\n",
    "print(y[:10])        # first 10 labels\n",
    "print(X[0][:10])     # first 10 pixel values of first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3eb7e-a436-40b8-886b-c4fe575cb9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 48, 48, 1)  # (samples, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9137e-9bbd-48b6-a779-d445268d883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3a2af-d9ac-4af4-b0a0-84f19f26fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[data['Usage'] == 'Training']\n",
    "y_train = y[data['Usage'] == 'Training']\n",
    "\n",
    "X_val = X[data['Usage'] == 'PublicTest']\n",
    "y_val = y[data['Usage'] == 'PublicTest']\n",
    "\n",
    "X_test = X[data['Usage'] == 'PrivateTest']\n",
    "y_test = y[data['Usage'] == 'PrivateTest']\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b491aae-d195-4878-9111-6ed375d03122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one image from training set\n",
    "index = 10\n",
    "plt.imshow(X_train[index].reshape(48,48), cmap='gray')\n",
    "plt.title(f\"Label: {y_train[index]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2196541-3fc0-4ca3-9e64-6d4b66d9f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emotion_dict = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}\n",
    "\n",
    "index = 10\n",
    "plt.imshow(X_train[index].reshape(48,48), cmap='gray')\n",
    "plt.title(f\"Emotion: {emotion_dict[y_train[index]]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b879cf5-d536-4d80-b968-c7b40533248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 50   # try any number from 0 to len(X_train)-1\n",
    "plt.imshow(X_train[index].reshape(48,48), cmap='gray')\n",
    "plt.title(f\"Emotion: {emotion_dict[y_train[index]]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76381a-7dd4-4571-bb48-50b3dab6ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(12):   # show first 12 images\n",
    "    plt.subplot(3, 4, i+1)   # 3 rows, 4 columns\n",
    "    plt.imshow(X_train[i].reshape(48,48), cmap='gray')\n",
    "    plt.title(emotion_dict[y_train[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fb445-9f55-4f59-9652-1c24f52ed0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the arrays\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf3175-f3fc-46a3-843c-1cbef32ec10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b78533-8b35-4022-9328-58128d21c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddca291-1bca-440d-8254-e5329ad55e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e78834-218f-47d8-92bd-8b256984cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c25eb7-f317-4eed-9e5a-a1fef6daf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "\n",
    "    # 1st Convolution Layer\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # 2nd Convolution Layer\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # 3rd Convolution Layer\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten layer\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Fully connected layer\n",
    "    layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer (7 classes)\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Check summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb4104-21cc-4ab7-8220-94005be8a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=25,             # run 25 times through the dataset\n",
    "    batch_size=64,         # train in groups of 64 images\n",
    "    validation_split=0.2,  # 20% of training data for validation\n",
    "    verbose=1              # show progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80bbd6-c487-44f4-ade7-dbbb0d8c8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393dbf5-0277-4070-8646-71f27efa0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38b93e-7ec2-47be-bfc2-2b0a27c97dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 48, 48, 1).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6be21c-3271-49d1-99a2-642ff247cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV file\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "print(data.head())   # check first few rows\n",
    "print(data.shape)    # total rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d0b69-1e53-4a02-be3d-727a989b66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"c:/Users/Admin/Desktop/MoodMate/data/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978627e2-834d-4c31-9976-8c6311155846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d0aab-f48d-4fd0-98a8-d90bdb7c66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d889e-ac0e-421f-9e8c-a1e29fd08ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388e956-6daf-4be4-ad7e-23a0db2d8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the FER2013 dataset\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "# Step 2: Convert the 'pixels' column (string of numbers) into numpy arrays\n",
    "X = np.array([np.fromstring(pixels, sep=' ') for pixels in data['pixels']])\n",
    "\n",
    "# Step 3: Extract the emotion labels\n",
    "y = data['emotion'].values\n",
    "\n",
    "# Step 4: Reshape the images to 48x48 pixels with 1 color channel (grayscale)\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "\n",
    "# Step 5: Normalize the pixel values (0 to 1 range)\n",
    "X = X / 255.0\n",
    "\n",
    "# Step 6: Split into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e57e8-8e61-4635-b9d7-2ddbb451c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3b348-b559-433a-b192-cdf7cb192aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\\fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b2ef9-3b3f-46b2-9bfe-2c1887042158",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdfb43-d0d0-4827-bdaf-6e144fac8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b88ecd-e1f5-4d99-87ab-9cd41c3107ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2a29f-3d48-4bcf-a8f3-fbd06f44d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\MoodMate\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a53d75-1b94-43a9-b1a4-6040d704867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Admin/Desktop/MoodMate/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b1458-405c-4434-8162-e1582f55359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"exists:\", os.path.exists(\"fer2013.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03bb6f-2670-4ae0-b19b-6e2291dcb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"exists:\", os.path.exists(\"fer2013.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e741876-13e7-4875-99eb-b07e64eea0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be7097a2-45da-46ca-8ad6-09377b551976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6d89bd-1453-43fd-96b8-08c296e8ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\MoodMate\\notebooks\\fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4cd27c-0165-421f-8aaf-45b21a697b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target labels\n",
    "y = data['emotion'].values\n",
    "\n",
    "# Convert pixel values to numpy arrays\n",
    "X = np.array([np.fromstring(pixels, sep=' ') for pixels in data['pixels']])\n",
    "\n",
    "# Reshape to 48x48 grayscale images\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "\n",
    "# Normalize (convert 0–255 to 0–1)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87612356-9cce-4973-8fc7-a9c6a9c89d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaaf9b0-f99d-44dc-add4-8c9a87a6474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (28709, 48, 48, 1) (28709,)\n",
      "Testing data shape: (7178, 48, 48, 1) (7178,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177a596c-f991-4c5a-99c1-e8d927d85333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m819,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Step 2a: Create the model structure\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')   # 7 emotions in FER2013 dataset\n",
    "])\n",
    "\n",
    "# Step 2b: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 2c: View model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c0a0db-261a-4ea0-9108-569fe02a5b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.3343 - loss: 1.6824 - val_accuracy: 0.4345 - val_loss: 1.4918\n",
      "Epoch 2/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.4343 - loss: 1.4765 - val_accuracy: 0.4681 - val_loss: 1.4198\n",
      "Epoch 3/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 100ms/step - accuracy: 0.4652 - loss: 1.3961 - val_accuracy: 0.4884 - val_loss: 1.3453\n",
      "Epoch 4/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.4891 - loss: 1.3428 - val_accuracy: 0.4972 - val_loss: 1.3144\n",
      "Epoch 5/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 102ms/step - accuracy: 0.5078 - loss: 1.2882 - val_accuracy: 0.5085 - val_loss: 1.2956\n",
      "Epoch 6/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 99ms/step - accuracy: 0.5197 - loss: 1.2471 - val_accuracy: 0.5258 - val_loss: 1.2579\n",
      "Epoch 7/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 101ms/step - accuracy: 0.5388 - loss: 1.2050 - val_accuracy: 0.5297 - val_loss: 1.2362\n",
      "Epoch 8/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 116ms/step - accuracy: 0.5587 - loss: 1.1580 - val_accuracy: 0.5393 - val_loss: 1.2246\n",
      "Epoch 9/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 102ms/step - accuracy: 0.5796 - loss: 1.1083 - val_accuracy: 0.5398 - val_loss: 1.2273\n",
      "Epoch 10/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.5966 - loss: 1.0651 - val_accuracy: 0.5369 - val_loss: 1.2263\n",
      "Epoch 11/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.6125 - loss: 1.0239 - val_accuracy: 0.5463 - val_loss: 1.2118\n",
      "Epoch 12/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 101ms/step - accuracy: 0.6245 - loss: 0.9811 - val_accuracy: 0.5450 - val_loss: 1.2436\n",
      "Epoch 13/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.6372 - loss: 0.9467 - val_accuracy: 0.5393 - val_loss: 1.2519\n",
      "Epoch 14/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6525 - loss: 0.9153 - val_accuracy: 0.5478 - val_loss: 1.2439\n",
      "Epoch 15/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 101ms/step - accuracy: 0.6669 - loss: 0.8709 - val_accuracy: 0.5465 - val_loss: 1.2804\n",
      "Epoch 16/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 103ms/step - accuracy: 0.6787 - loss: 0.8329 - val_accuracy: 0.5479 - val_loss: 1.2862\n",
      "Epoch 17/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.6884 - loss: 0.8062 - val_accuracy: 0.5429 - val_loss: 1.3398\n",
      "Epoch 18/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 103ms/step - accuracy: 0.6996 - loss: 0.7781 - val_accuracy: 0.5497 - val_loss: 1.3491\n",
      "Epoch 19/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.7039 - loss: 0.7539 - val_accuracy: 0.5463 - val_loss: 1.4291\n",
      "Epoch 20/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.7176 - loss: 0.7184 - val_accuracy: 0.5437 - val_loss: 1.4471\n",
      "Epoch 21/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 107ms/step - accuracy: 0.7279 - loss: 0.6978 - val_accuracy: 0.5485 - val_loss: 1.4218\n",
      "Epoch 22/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 106ms/step - accuracy: 0.7331 - loss: 0.6812 - val_accuracy: 0.5474 - val_loss: 1.4760\n",
      "Epoch 23/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.7408 - loss: 0.6575 - val_accuracy: 0.5439 - val_loss: 1.5255\n",
      "Epoch 24/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 106ms/step - accuracy: 0.7444 - loss: 0.6366 - val_accuracy: 0.5531 - val_loss: 1.5749\n",
      "Epoch 25/25\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.7551 - loss: 0.6102 - val_accuracy: 0.5525 - val_loss: 1.5643\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,                   # training data\n",
    "    epochs=25,                          # number of training rounds\n",
    "    batch_size=64,                      # how many samples per update\n",
    "    validation_data=(X_test, y_test),   # test data for validation\n",
    "    verbose=1                           # shows progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa180175-bc94-4224-b415-c9e5f15ee43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'fer2013/train',\n",
    "    image_size=(48,48),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961b450-1504-4889-8f9c-3fefb7cf350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.12),\n",
    "    tf.keras.layers.RandomZoom(0.12),\n",
    "])\n",
    "\n",
    "# Take one batch of images\n",
    "for images, labels in train_dataset.take(1):\n",
    "    sample_image = images[0:1]  # pick first image from batch\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    augmented_image = data_augmentation(sample_image)\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(tf.cast(tf.clip_by_value(augmented_image[0], 0, 1), tf.float32))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa301af-e28a-443d-b02c-20b8de75f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- 1️⃣ Create the augmentation layer ---\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.12),\n",
    "    tf.keras.layers.RandomZoom(0.12),\n",
    "])\n",
    "\n",
    "# --- 2️⃣ Get one batch of images from FER2013 dataset ---\n",
    "for images, labels in train_dataset.take(1):\n",
    "    sample_image = images[0]  # pick first image in batch\n",
    "\n",
    "# --- 3️⃣ FER2013 is grayscale, convert to RGB if needed ---\n",
    "if sample_image.shape[-1] == 1:\n",
    "    sample_image = tf.image.grayscale_to_rgb(sample_image)\n",
    "\n",
    "# --- 4️⃣ Add batch dimension for augmentation ---\n",
    "sample_image = tf.expand_dims(sample_image, 0)\n",
    "\n",
    "# --- 5️⃣ Plot augmented images ---\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    augmented_image = data_augmentation(sample_image, training=True)\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(augmented_image[0].numpy())\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cc07b6-b054-4ff8-b85f-1d5ced74fc50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72e21f6-4755-4594-87be-02e180805537",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a554f7-c4fc-4322-ab94-44fd0ce946da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory path/to/test",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,         \u001b[38;5;66;03m# your test folder path\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m),\n\u001b[0;32m      6\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# FER-2013 is grayscale\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:232\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mindex_directory(\n\u001b[0;32m    233\u001b[0m     directory,\n\u001b[0;32m    234\u001b[0m     labels,\n\u001b[0;32m    235\u001b[0m     formats\u001b[38;5;241m=\u001b[39mALLOWLIST_FORMATS,\n\u001b[0;32m    236\u001b[0m     class_names\u001b[38;5;241m=\u001b[39mclass_names,\n\u001b[0;32m    237\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    238\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    239\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m    240\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:530\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    532\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory path/to/test"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"path/to/test\",         # your test folder path\n",
    "    image_size=(48, 48),\n",
    "    color_mode=\"grayscale\", # FER-2013 is grayscale\n",
    "    batch_size=32\n",
    ")\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a8d036-1ca9-4a98-a754-9b3b39593d99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory /content/FER-2013/test",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/FER-2013/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m),\n\u001b[0;32m      6\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# or \"rgb\" if grayscale not supported\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:232\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mindex_directory(\n\u001b[0;32m    233\u001b[0m     directory,\n\u001b[0;32m    234\u001b[0m     labels,\n\u001b[0;32m    235\u001b[0m     formats\u001b[38;5;241m=\u001b[39mALLOWLIST_FORMATS,\n\u001b[0;32m    236\u001b[0m     class_names\u001b[38;5;241m=\u001b[39mclass_names,\n\u001b[0;32m    237\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    238\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    239\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m    240\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:530\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    532\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory /content/FER-2013/test"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"/content/FER-2013/test\",\n",
    "    image_size=(48, 48),\n",
    "    color_mode=\"grayscale\",   # or \"rgb\" if grayscale not supported\n",
    "    batch_size=32\n",
    ")\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b266b87b-4dbf-4e6c-b167-50f047e3d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce07c57-5f73-4e3b-a6bd-9ef12cdb24f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fer2013.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fer_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/fer2013.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fer_path)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fer2013.csv'"
     ]
    }
   ],
   "source": [
    "fer_path = \"data/fer2013.csv\"\n",
    "\n",
    "df = pd.read_csv(fer_path)\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "# Columns: emotion, pixels, Usage\n",
    "# emotion = numeric label (0–6), pixels = space-separated pixel values (48x48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f1da55-9ee6-460c-9a41-1aad4019f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 35887\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "fer_path = r\"C:\\Users\\Admin\\Desktop\\MoodMate\\data\\fer2013.csv\"\n",
    "df = pd.read_csv(fer_path)\n",
    "print(\"Rows:\", len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4a5d32-7b42-4a87-b231-32534349fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion_label\n",
      "Happy       8989\n",
      "Neutral     6198\n",
      "Sad         6077\n",
      "Fear        5121\n",
      "Angry       4953\n",
      "Surprise    4002\n",
      "Disgust      547\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}\n",
    "df[\"emotion_label\"] = df[\"emotion\"].map(emotion_labels)\n",
    "\n",
    "print(df[\"emotion_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15e515c-cc33-40ef-8283-71422e1a438e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Convert pixel strings to image arrays\n",
    "# ----------------------------------------------------------\n",
    "def string_to_image(pixel_string):\n",
    "    pixels = np.array(pixel_string.split(), dtype=\"float32\")\n",
    "    return pixels.reshape(48, 48)\n",
    "\n",
    "df[\"image\"] = df[\"pixels\"].apply(string_to_image)\n",
    "\n",
    "# Visualize a few samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(df[\"image\"][i], cmap=\"gray\")\n",
    "    ax.set_title(df[\"emotion_label\"][i])\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aca9e5a-0090-45c8-91b5-d467f8455c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3712148402.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    5. Prepare X and y arrays\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "5. Prepare X and y arrays\n",
    "# ----------------------------------------------------------\n",
    "X = np.stack(df[\"image\"].to_numpy())\n",
    "X = X / 255.0   # normalize to [0,1]\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "y = df[\"emotion\"].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbe5950-a820-4833-8fa8-4a6158b179ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (35887, 48, 48, 1)\n",
      "y shape: (35887,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------------------\n",
    "X = np.stack(df[\"image\"].to_numpy())\n",
    "X = X / 255.0   # normalize to [0,1]\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "y = df[\"emotion\"].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ad7488-5352-4190-8f9f-6a61acf244ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (25120, 48, 48, 1)\n",
      "Val:   (5383, 48, 48, 1)\n",
      "Test:  (5384, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# 6. Split into train / validation / test\n",
    "# ----------------------------------------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val:   {X_val.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d724e522-ed9a-468f-adaf-53c0b8ec23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Data augmentation (for model training)\n",
    "# ----------------------------------------------------------\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# show one augmented example\n",
    "sample = X_train[0].reshape(1, 48, 48, 1)\n",
    "for batch in train_gen.flow(sample, batch_size=1):\n",
    "    plt.imshow(batch[0].reshape(48, 48), cmap=\"gray\")\n",
    "    plt.title(\"Augmented Example\")\n",
    "    plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f59691-9e78-480f-80a5-43e210d8ecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FER-2013 preprocessing complete!\n",
      "Files saved in 'processed_data/' folder.\n"
     ]
    }
   ],
   "source": [
    "# 8. Save processed arrays\n",
    "# ----------------------------------------------------------\n",
    "os.makedirs(\"processed_data\", exist_ok=True)\n",
    "np.save(\"processed_data/X_train.npy\", X_train)\n",
    "np.save(\"processed_data/y_train.npy\", y_train)\n",
    "np.save(\"processed_data/X_val.npy\", X_val)\n",
    "np.save(\"processed_data/y_val.npy\", y_val)\n",
    "np.save(\"processed_data/X_test.npy\", X_test)\n",
    "np.save(\"processed_data/y_test.npy\", y_test)\n",
    "\n",
    "print(\"✅ FER-2013 preprocessing complete!\")\n",
    "print(\"Files saved in 'processed_data/' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810fec05-0b69-4280-92ee-f1f33b84c8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      4\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m      5\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPool2D(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m7\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m ])\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m     19\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    layers.MaxPool2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "          epochs=30, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ae58cc-0f91-4c32-a0d8-3c3963a3914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: ['X_test.npy', 'X_train.npy', 'X_val.npy', 'y_test.npy', 'y_train.npy', 'y_val.npy']\n",
      "X_train.shape, dtype: (25120, 48, 48, 1) float32\n",
      "y_train.shape, dtype: (25120,) int64\n",
      "X_val.shape, dtype: (5383, 48, 48, 1) float32\n",
      "y_val.shape, dtype: (5383,) int64\n",
      "X_train min/max: 0.0 1.0\n",
      "y_train unique: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1) confirm files exist\n",
    "print(\"Files:\", os.listdir(\"processed_data\") if os.path.exists(\"processed_data\") else \"processed_data missing\")\n",
    "\n",
    "# 2) load and inspect shapes / dtypes\n",
    "X_train = np.load(\"processed_data/X_train.npy\")\n",
    "y_train = np.load(\"processed_data/y_train.npy\")\n",
    "X_val = np.load(\"processed_data/X_val.npy\")\n",
    "y_val = np.load(\"processed_data/y_val.npy\")\n",
    "print(\"X_train.shape, dtype:\", X_train.shape, X_train.dtype)\n",
    "print(\"y_train.shape, dtype:\", y_train.shape, y_train.dtype)\n",
    "print(\"X_val.shape, dtype:\", X_val.shape, X_val.dtype)\n",
    "print(\"y_val.shape, dtype:\", y_val.shape, y_val.dtype)\n",
    "\n",
    "# 3) inspect sample values\n",
    "print(\"X_train min/max:\", X_train.min(), X_train.max())\n",
    "print(\"y_train unique:\", np.unique(y_train)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56bebcb6-07cf-4c2b-9330-9db9d0418f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25120, 48, 48, 1) (25120,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"processed_data/X_train.npy\")\n",
    "y_train = np.load(\"processed_data/y_train.npy\")\n",
    "X_val   = np.load(\"processed_data/X_val.npy\")\n",
    "y_val   = np.load(\"processed_data/y_val.npy\")\n",
    "X_test  = np.load(\"processed_data/X_test.npy\")\n",
    "y_test  = np.load(\"processed_data/y_test.npy\")\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0eb2a8-ec2d-4556-a0e0-543080f44ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m819,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">839,047</span> (3.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m839,047\u001b[0m (3.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Dense(7, activation='softmax')  # 7 emotion classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8be88e-2be0-4a2b-99c1-5b3c84ea3e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 86ms/step - accuracy: 0.3292 - loss: 1.6909 - val_accuracy: 0.4276 - val_loss: 1.5131\n",
      "Epoch 2/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.4272 - loss: 1.4917 - val_accuracy: 0.4746 - val_loss: 1.3962\n",
      "Epoch 3/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - accuracy: 0.4637 - loss: 1.3979 - val_accuracy: 0.4821 - val_loss: 1.3447\n",
      "Epoch 4/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.4914 - loss: 1.3256 - val_accuracy: 0.5047 - val_loss: 1.3013\n",
      "Epoch 5/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.5217 - loss: 1.2649 - val_accuracy: 0.5138 - val_loss: 1.2737\n",
      "Epoch 6/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.5363 - loss: 1.2158 - val_accuracy: 0.5233 - val_loss: 1.2467\n",
      "Epoch 7/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - accuracy: 0.5586 - loss: 1.1583 - val_accuracy: 0.5239 - val_loss: 1.2369\n",
      "Epoch 8/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.5772 - loss: 1.1108 - val_accuracy: 0.5341 - val_loss: 1.2305\n",
      "Epoch 9/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.5979 - loss: 1.0604 - val_accuracy: 0.5311 - val_loss: 1.2495\n",
      "Epoch 10/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.6205 - loss: 1.0040 - val_accuracy: 0.5378 - val_loss: 1.2599\n",
      "Epoch 11/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.6380 - loss: 0.9523 - val_accuracy: 0.5445 - val_loss: 1.2649\n",
      "Epoch 12/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 80ms/step - accuracy: 0.6580 - loss: 0.9002 - val_accuracy: 0.5460 - val_loss: 1.2811\n",
      "Epoch 13/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.6789 - loss: 0.8496 - val_accuracy: 0.5385 - val_loss: 1.2801\n",
      "Epoch 14/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.6966 - loss: 0.8003 - val_accuracy: 0.5473 - val_loss: 1.3622\n",
      "Epoch 15/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7100 - loss: 0.7655 - val_accuracy: 0.5463 - val_loss: 1.3865\n",
      "Epoch 16/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.7222 - loss: 0.7305 - val_accuracy: 0.5488 - val_loss: 1.4317\n",
      "Epoch 17/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.7376 - loss: 0.6836 - val_accuracy: 0.5398 - val_loss: 1.4153\n",
      "Epoch 18/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.7501 - loss: 0.6432 - val_accuracy: 0.5456 - val_loss: 1.4613\n",
      "Epoch 19/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 88ms/step - accuracy: 0.7646 - loss: 0.6117 - val_accuracy: 0.5387 - val_loss: 1.5147\n",
      "Epoch 20/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.7765 - loss: 0.5775 - val_accuracy: 0.5346 - val_loss: 1.5869\n",
      "Epoch 21/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 93ms/step - accuracy: 0.7887 - loss: 0.5487 - val_accuracy: 0.5449 - val_loss: 1.7003\n",
      "Epoch 22/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 88ms/step - accuracy: 0.7916 - loss: 0.5285 - val_accuracy: 0.5411 - val_loss: 1.6465\n",
      "Epoch 23/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - accuracy: 0.8046 - loss: 0.5024 - val_accuracy: 0.5346 - val_loss: 1.7292\n",
      "Epoch 24/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 91ms/step - accuracy: 0.8084 - loss: 0.4868 - val_accuracy: 0.5374 - val_loss: 1.8253\n",
      "Epoch 25/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.8188 - loss: 0.4669 - val_accuracy: 0.5365 - val_loss: 1.8903\n",
      "Epoch 26/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8255 - loss: 0.4444 - val_accuracy: 0.5443 - val_loss: 1.9373\n",
      "Epoch 27/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 85ms/step - accuracy: 0.8299 - loss: 0.4319 - val_accuracy: 0.5402 - val_loss: 2.0248\n",
      "Epoch 28/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.8337 - loss: 0.4165 - val_accuracy: 0.5400 - val_loss: 2.0286\n",
      "Epoch 29/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.8426 - loss: 0.3953 - val_accuracy: 0.5437 - val_loss: 2.1955\n",
      "Epoch 30/30\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - accuracy: 0.8451 - loss: 0.3886 - val_accuracy: 0.5411 - val_loss: 2.2482\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cdf9af-bc86-40f1-b294-a4743234ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5366 - loss: 2.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5365899205207825\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"processed_data/X_test.npy\")\n",
    "y_test = np.load(\"processed_data/y_test.npy\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "model.save(\"models/emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f648102-ed10-4585-b27a-dec8c4406251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1bcb64-175d-4991-9a6c-78389a213fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b4e39a-13c7-4e18-99de-2199ce003f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must call `compile()` before using the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(datagen\u001b[38;5;241m.\u001b[39mflow(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m      2\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m      3\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:1050\u001b[0m, in \u001b[0;36mTrainer._assert_compile_called\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1050\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You must call `compile()` before using the model."
     ]
    }
   ],
   "source": [
    "model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341767eb-e68c-4c39-b1d7-cce40358b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4814de9-afcb-4916-ba26-2bec94310f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (25120, 48, 48, 1) Val: (5383, 48, 48, 1) Test: (5384, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.load(\"processed_data/X_train.npy\")\n",
    "y_train = np.load(\"processed_data/y_train.npy\")\n",
    "X_val   = np.load(\"processed_data/X_val.npy\")\n",
    "y_val   = np.load(\"processed_data/y_val.npy\")\n",
    "X_test  = np.load(\"processed_data/X_test.npy\")\n",
    "y_test  = np.load(\"processed_data/y_test.npy\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79c1e2-2da9-4373-a915-d70819e8d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Resize grayscale 48x48 -> RGB 224x224\n",
    "def resize_to_rgb(x):\n",
    "    x = tf.image.grayscale_to_rgb(tf.convert_to_tensor(x))\n",
    "    x = tf.image.resize(x, (224,224))\n",
    "    return x\n",
    "\n",
    "X_train = tf.stack([resize_to_rgb(img) for img in X_train])\n",
    "X_val   = tf.stack([resize_to_rgb(img) for img in X_val])\n",
    "X_test  = tf.stack([resize_to_rgb(img) for img in X_test])\n",
    "\n",
    "X_train = preprocess_input(X_train)\n",
    "X_val   = preprocess_input(X_val)\n",
    "X_test  = preprocess_input(X_test)\n",
    "\n",
    "print(\"Resized:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084c8a4-bfdb-4cea-a3b8-69087bb92943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0].numpy().astype(\"uint8\"))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d8f67-851f-4f6d-95e0-95e407c26025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
