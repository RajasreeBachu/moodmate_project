üéµ MoodMate: AI Emotion Detection & Music Recommendation System

An intelligent system that detects user emotions and recommends music in real time.


---

üìå Project Overview

MoodMate is an AI-powered application that predicts a user‚Äôs emotional state from facial expressions or text input and recommends music that aligns with or improves their mood.
It integrates Computer Vision / NLP with Music Recommendation Systems to deliver an interactive, emotion-aware experience.


---

üéØ Objectives

Detect emotions using facial images (FER-2013) or text input.

Build a content-based music recommendation engine.

Map user emotions to suitable music genres / tags.

Develop an interactive UI for real-time emotion ‚Üí music suggestions.

Deploy a complete end-to-end system.



---

‚úÖ Key Outcomes

Hands-on experience in image preprocessing, emotion classification, and content-based recommendation.

Working knowledge of MobileNetV2 / CNN / BERT (optional).

Complete integration of ML models with a user-friendly interface.

A fully functional prototype with real-time predictions.



---

üìÇ Datasets Used

1. Emotion Recognition

FER-2013 (Kaggle)
Grayscale 48√ó48 facial emotion dataset
Classes: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral


2. Music Recommendation

Million Song Dataset (subset)

Last.fm Tags Dataset

Optional: RAVDESS for multimodal audio emotion analysis



---

üß± System Architecture

+-------------------------+
               |   User Input (Image/Text)|
               +-----------+-------------+
                           |
                           v
                +-----------------------+
                | Emotion Detection     |
                | (CNN / MobileNetV2)   |
                +-----------+-----------+
                            |
                            v
                +-----------------------+
                | Emotion ‚Üí Music Mapping|
                +-----------+-----------+
                            |
                            v
                +-----------------------+
                | Recommendation Engine |
                | (TF-IDF / Cosine Sim) |
                +-----------+-----------+
                            |
                            v
                +-----------------------+
                | Streamlit UI Output   |
                +-----------------------+


---

üß© Modules Implemented

1Ô∏è‚É£ Data Collection & Preprocessing

Load and clean FER-2013 CSV dataset

Convert pixel strings ‚Üí 48√ó48 grayscale images

Normalize and split into Train / Validation / Test

Process Last.fm music tags, genres, moods

Extract features: TF-IDF tags, tempo, energy, valence



---

2Ô∏è‚É£ Emotion Detection Module

Method 1: CNN from scratch

Method 2 (recommended): MobileNetV2 pretrained model

Resize images to 224√ó224√ó3

Freeze + fine-tune layers

Achieve 75‚Äì85% accuracy




---

3Ô∏è‚É£ Music Recommendation Engine

Content-based filtering

TF-IDF vectorization of music tags

Cosine similarity for ranking songs

Emotion ‚Üí Tag mapping

Happy    ‚Üí pop, dance, upbeat  
Sad      ‚Üí acoustic, mellow, low-energy  
Angry    ‚Üí rock, metal, fast-tempo  
Calm     ‚Üí ambient, instrumental, soft



---

4Ô∏è‚É£ UI & Real-Time Integration

Interactive app built using Streamlit

Features:

Upload face image

Detect emotion

Generate recommended playlist

Display top 5‚Äì10 songs with metadata




---

5Ô∏è‚É£ Deployment & Final Output

Export model: mobilenetv2_emotion.keras

Streamlit front-end

Documentation + demo video
